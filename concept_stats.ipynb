{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime \n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to the mmkg elastcsearch server\n",
    "es = Elasticsearch([\"http://130.220.208.86:9200\"])\n",
    "topic_dict = {\"beef ban\":\"crl01\", \"gun control\":\"csc02\", \"gay marriage\":\"chr01\", \n",
    "              \"climate change\":\"cst01\", \"refugee\":\"cbp02\"}\n",
    "\n",
    "concept_types = ('DBpedia:Place', 'DBpedia:Country', 'DBpedia:City', 'DBpedia:Organisation', 'DBpedia:Person', \n",
    "                'DBpedia:Company', 'DBpedia:Work', 'DBpedia:OfficeHolder', 'DBpedia:Event', \n",
    "                 'DBpedia:EthnicGroup', 'DBpedia:Disease', 'DBpedia:MilitaryConflict', \n",
    "                 'DBpedia:MusicalWork', 'Other', 'NA')\n",
    "# excluded: \n",
    "# 'DBpedia:Settlement' (subclass of PopulatedPlace)\n",
    "# 'DBpedia:Agent', (superclass of person and organization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stretch goal: enable scrolling \n",
    "tpc_str = 'beef ban'\n",
    "max_docs = 40000\n",
    "page_size = 500\n",
    "\n",
    "index = \"mmkg-doc-%s\" % topic_dict[tpc_str]\n",
    "query = {\"size\": page_size,\n",
    "         \"query\": {\"match_all\": {} }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# query for the first batch\n",
    "res = es.search(index=index, body=query, _source=True, scroll=\"1h\")\n",
    "scoll_id = res['_scroll_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-20 13:19:17.132983 processing docs          1 to        500\n",
      "2017-09-20 13:19:20.114562 processing docs        501 to       1000\n",
      "2017-09-20 13:19:23.237830 processing docs       1001 to       1500\n",
      "2017-09-20 13:19:26.566448 processing docs       1501 to       2000\n",
      "2017-09-20 13:19:28.474424 processing docs       2001 to       2500\n",
      "2017-09-20 13:19:30.777282 processing docs       2501 to       3000\n",
      "2017-09-20 13:19:33.226301 processing docs       3001 to       3500\n",
      "2017-09-20 13:19:35.235437 processing docs       3501 to       4000\n",
      "2017-09-20 13:19:37.616728 processing docs       4001 to       4500\n",
      "2017-09-20 13:19:39.124385 processing docs       4501 to       5000\n",
      "2017-09-20 13:19:41.061077 processing docs       5001 to       5500\n",
      "2017-09-20 13:19:42.682882 processing docs       5501 to       6000\n",
      "2017-09-20 13:19:43.217035 processing docs       6001 to       6500\n",
      "2017-09-20 13:19:43.991564 processing docs       6501 to       7000\n",
      "2017-09-20 13:19:45.526665 processing docs       7001 to       7500\n",
      "2017-09-20 13:19:46.658430 processing docs       7501 to       8000\n",
      "2017-09-20 13:19:48.077754 processing docs       8001 to       8500\n",
      "2017-09-20 13:19:49.346049 processing docs       8501 to       9000\n",
      "2017-09-20 13:19:51.154253 processing docs       9001 to       9500\n",
      "2017-09-20 13:19:52.574217 processing docs       9501 to      10000\n",
      "2017-09-20 13:19:54.235531 processing docs      10001 to      10500\n",
      "2017-09-20 13:19:55.171625 processing docs      10501 to      11000\n",
      "2017-09-20 13:19:56.471059 processing docs      11001 to      11500\n",
      "2017-09-20 13:19:58.260873 processing docs      11501 to      12000\n",
      "2017-09-20 13:19:59.598458 processing docs      12001 to      12500\n",
      "2017-09-20 13:20:00.619709 processing docs      12501 to      13000\n",
      "2017-09-20 13:20:02.256154 processing docs      13001 to      13500\n",
      "2017-09-20 13:20:04.944449 processing docs      13501 to      14000\n",
      "2017-09-20 13:20:07.048545 processing docs      14001 to      14500\n",
      "2017-09-20 13:20:09.256464 processing docs      14501 to      15000\n",
      "2017-09-20 13:20:10.735799 processing docs      15001 to      15500\n",
      "2017-09-20 13:20:13.300640 processing docs      15501 to      16000\n",
      "2017-09-20 13:20:15.382920 processing docs      16001 to      16500\n",
      "2017-09-20 13:20:17.202074 processing docs      16501 to      17000\n",
      "2017-09-20 13:20:18.385287 processing docs      17001 to      17500\n",
      "2017-09-20 13:20:19.361238 processing docs      17501 to      18000\n",
      "2017-09-20 13:20:20.502648 processing docs      18001 to      18500\n",
      "2017-09-20 13:20:22.116946 processing docs      18501 to      19000\n",
      "2017-09-20 13:20:23.894948 processing docs      19001 to      19500\n",
      "2017-09-20 13:20:25.223699 processing docs      19501 to      20000\n",
      "2017-09-20 13:20:26.195292 processing docs      20001 to      20500\n",
      "2017-09-20 13:20:27.297161 processing docs      20501 to      21000\n",
      "2017-09-20 13:20:28.318271 processing docs      21001 to      21500\n",
      "2017-09-20 13:20:29.238804 processing docs      21501 to      22000\n",
      "2017-09-20 13:20:30.820502 processing docs      22001 to      22500\n",
      "2017-09-20 13:20:34.905559 processing docs      22501 to      23000\n",
      "2017-09-20 13:20:37.525449 processing docs      23001 to      23500\n",
      "2017-09-20 13:20:41.545144 processing docs      23501 to      24000\n",
      "2017-09-20 13:20:43.861326 processing docs      24001 to      24500\n",
      "2017-09-20 13:20:44.962971 processing docs      24501 to      25000\n",
      "2017-09-20 13:20:46.342444 processing docs      25001 to      25500\n",
      "2017-09-20 13:20:47.775246 processing docs      25501 to      26000\n",
      "2017-09-20 13:20:50.057081 processing docs      26001 to      26500\n",
      "2017-09-20 13:20:51.848070 processing docs      26501 to      27000\n",
      "2017-09-20 13:20:52.943917 processing docs      27001 to      27500\n",
      "2017-09-20 13:20:54.012678 processing docs      27501 to      28000\n",
      "2017-09-20 13:20:55.098474 processing docs      28001 to      28500\n",
      "2017-09-20 13:20:56.208802 processing docs      28501 to      29000\n",
      "2017-09-20 13:20:57.357976 processing docs      29001 to      29500\n",
      "2017-09-20 13:20:59.370361 processing docs      29501 to      30000\n",
      "2017-09-20 13:21:00.522777 processing docs      30001 to      30500\n",
      "2017-09-20 13:21:01.778569 processing docs      30501 to      31000\n",
      "2017-09-20 13:21:03.422186 processing docs      31001 to      31500\n",
      "2017-09-20 13:21:05.273210 processing docs      31501 to      32000\n",
      "2017-09-20 13:21:07.301291 processing docs      32001 to      32500\n",
      "2017-09-20 13:21:10.206225 processing docs      32501 to      33000"
     ]
    }
   ],
   "source": [
    "\n",
    "# goal 1 - produce concept frequency graphs\n",
    "\n",
    "df_concept = pd.DataFrame(data=None, columns=['count']+ list(concept_types)) + ['SurfaceForms']\n",
    "#df_type = pd.DataFrame(data=None, columns=['count'])\n",
    "#df_type.ix[\"NA\", 'count'] = 0\n",
    "\n",
    "cum_doc_cnt = 0\n",
    "no_concept_count = {}\n",
    "\n",
    "while cum_doc_cnt < max_docs:\n",
    "    print(\"{} processing docs {:10.0f} to {:10.0f}\".format(datetime.now(), cum_doc_cnt+1, cum_doc_cnt+page_size) )\n",
    "    \n",
    "    for doc in res['hits']['hits']:\n",
    "        d = doc['_source']\n",
    "        mo = d['timestamp'][:8]\n",
    "        if 'entities' in d:\n",
    "            for e in d['entities']:\n",
    "                if e['concept'] not in df_concept.index:\n",
    "                    # add the row for this concept\n",
    "                    df_concept.ix[e['concept'], 'count'] = 0\n",
    "                    # set concept type flags \n",
    "                    if 'types' in e:\n",
    "                        for tt in e['types']:\n",
    "                            if tt in concept_types:\n",
    "                                df_concept.ix[e['concept'], tt] = 1\n",
    "                            else:\n",
    "                                df_concept.ix[e['concept'], \"Other\"] = 1\n",
    "                    else:\n",
    "                        df_concept.ix[e['concept'], \"NA\"] = 1\n",
    "                # increment concept count\n",
    "                df_concept.ix[e['concept'], 'count'] += 1   \n",
    "        else:\n",
    "            if d[\"type\"] not in no_concept_count:\n",
    "                no_concept_count[d['type']] = 0\n",
    "            no_concept_count[d['type']] += 1\n",
    "    # get the next page \n",
    "    res = es.scroll(scroll='1h', scroll_id=scoll_id)\n",
    "    cum_doc_cnt += len(res['hits']['hits'])\n",
    "\n",
    "# goal 2 - color by type\n",
    "# goal 3 - concept frequencies over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(no_concept_count)\n",
    "pickle.dump({'df_concept':df_concept}, \n",
    "            open(os.path.join('../data', 'concept_stats.'+tpc_str+'.'+str(cum_doc_cnt)+'.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "sns.set_context(\"talk\", font_scale=1.)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "ax1.autoscale(enable=True, tight=True)\n",
    "ax1.loglog([i for i in range(len(df_concept))], df_concept['count'])\n",
    "ax1.set_xlabel('concept rank')\n",
    "ax1.set_ylabel('concept frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### df_concept.sort_values(by=\"count\", axis=0, ascending=False, inplace=True)\n",
    "df_concept.fillna(value=0, inplace=True)\n",
    "df_concept.head(20)\n",
    "\n",
    "# print out a few percentile spots of the table \n",
    "num_concept = len(df_concept)\n",
    "print(num_concept)\n",
    "idx_print = [i for i in range(10)]\n",
    "for offset in [0, 100, 500, 10000]:\n",
    "    cur_idx = [i + offset for i in idx_print]\n",
    "    #print(cur_idx)\n",
    "    print( df_concept.iloc[cur_idx, 0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_type.sort_values(by=\"count\", axis=0, ascending=False, inplace=True)\n",
    "print( df_type.head(60) )\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "sns.set_context(\"talk\", font_scale=1.)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax1.semilogy([i for i in range(len(df_type))], df_type['count'])\n",
    "#ax1.set_semilogy(True)\n",
    "\n",
    "clrs = sns.color_palette(\"muted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ( len(res['hits']['hits']) )\n",
    "print ( len(res['hits']['hits'][0]['_source']['entities']) )\n",
    "print ( res['hits']['hits'][0]['_source']['timestamp'] ) \n",
    "#res['hits']['hits'][0]['_source']['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "         \"size\": 2,\n",
    "         \"query\": {\"match_all\": {} }\n",
    "         }\n",
    "res = es.search(index=index, body=query, _source=True, scroll=\"5m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoll_id = res['_scroll_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoll_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = es.scroll(scroll='5m', scroll_id=scoll_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = es.scroll(scroll='5m', scroll_id=scoll_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([i for i in range(-5, 5)]) +  5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
